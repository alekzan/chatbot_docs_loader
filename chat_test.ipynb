{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# airregio_graph_crm.py\n",
    "import operator\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from typing import Annotated, TypedDict, Sequence, Optional\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from pydantic import BaseModel\n",
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "\n",
    "\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Extract Data from Chat\"\n",
    "\n",
    "gpt = \"gpt-4o-mini\"\n",
    "# llm = ChatOpenAI(model=gpt, temperature=0.2)\n",
    "llama_3_2 = \"llama-3.2-90b-vision-preview\"\n",
    "llm = ChatGroq(model=llama_3_2, temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_docs_and_get_retriever(\n",
    "    doc_path: str,\n",
    "    persist_directory: str = \"./data/rag/chroma_langchain_db\",\n",
    "    collection_name: str = \"user_data\",\n",
    "    k: int = 4,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load a document (PDF or DOCX), split its content, add it to a Chroma vector store, and return a retriever.\n",
    "    \n",
    "    Args:\n",
    "        doc_path: Path to the document file (PDF or DOCX).\n",
    "        persist_directory: Directory where the Chroma vector store will be persisted.\n",
    "        collection_name: Name of the collection in the vector store.\n",
    "        k: Number of documents to retrieve in similarity searches.\n",
    "    \n",
    "    Returns:\n",
    "        A retriever object for querying the vector store.\n",
    "    \"\"\"\n",
    "    # Step 1: Determine document type and load it\n",
    "    if doc_path.endswith(\".pdf\"):\n",
    "        try:\n",
    "            loader = PyPDFLoader(doc_path)\n",
    "            docs = loader.load_and_split()\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading PDF: {e}\")\n",
    "            return None\n",
    "    elif doc_path.endswith(\".docx\"):\n",
    "        try:\n",
    "            loader = Docx2txtLoader(doc_path)\n",
    "            docs = loader.load()\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading DOCX: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"Unsupported file format. Please provide a .pdf or .docx file.\")\n",
    "        return None\n",
    "\n",
    "    # Step 2: Split the text into manageable chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50,\n",
    "        separators=[\n",
    "            \"# \", \"## \", \"### \", \"\\n\\n\", \"\\n- \", \". \", \" \"\n",
    "        ],\n",
    "    )\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "\n",
    "    # Step 3: Initialize or load Chroma vector store\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    if os.path.exists(persist_directory):\n",
    "        # Load existing vector store\n",
    "        vector_store = Chroma(\n",
    "            persist_directory=persist_directory,\n",
    "            embedding_function=embeddings,\n",
    "            collection_name=collection_name,\n",
    "        )\n",
    "        # Add new documents to the existing vector store\n",
    "        vector_store.add_documents(splits)\n",
    "    else:\n",
    "        # Create a new vector store and add documents\n",
    "        vector_store = Chroma.from_documents(\n",
    "            documents=splits,\n",
    "            embedding=embeddings,\n",
    "            persist_directory=persist_directory,\n",
    "            collection_name=collection_name,\n",
    "        )\n",
    "\n",
    "    return \"All Data added\"\n",
    "\n",
    "def process_text_as_retriever(text: str):\n",
    "    \"\"\"\n",
    "    Process plain text, split it into chunks, add it to a Chroma vector store, and return a retriever.\n",
    "    \n",
    "    Args:\n",
    "        text: Plain text to be added to the vector store.\n",
    "    \n",
    "    Returns:\n",
    "        A retriever object for querying the vector store.\n",
    "    \"\"\"\n",
    "    # Hard-coded parameters\n",
    "    persist_directory = \"./data/rag/chroma_langchain_db\"\n",
    "    collection_name = \"user_data\"\n",
    "    k = 4\n",
    "\n",
    "    # Step 1: Convert text into a Document object\n",
    "    from langchain_core.documents import Document\n",
    "\n",
    "    docs = [Document(page_content=text)]\n",
    "\n",
    "    # Step 2: Split the text into manageable chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50,\n",
    "        separators=[\n",
    "            \"# \", \"## \", \"### \", \"\\n\\n\", \"\\n- \", \". \", \" \"\n",
    "        ],\n",
    "    )\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "\n",
    "    # Step 3: Initialize or load Chroma vector store\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    if os.path.exists(persist_directory):\n",
    "        # Load existing vector store\n",
    "        vector_store = Chroma(\n",
    "            persist_directory=persist_directory,\n",
    "            embedding_function=embeddings,\n",
    "            collection_name=collection_name,\n",
    "        )\n",
    "        # Add new documents to the existing vector store\n",
    "        vector_store.add_documents(splits)\n",
    "    else:\n",
    "        # Create a new vector store and add documents\n",
    "        vector_store = Chroma.from_documents(\n",
    "            documents=splits,\n",
    "            embedding=embeddings,\n",
    "            persist_directory=persist_directory,\n",
    "            collection_name=collection_name,\n",
    "        )\n",
    "\n",
    "    # Step 4: Create and return the retriever\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\": k})\n",
    "    return retriever\n",
    "\n",
    "\n",
    "def recreate_retriever(persist_directory: str = \"./data/rag/chroma_langchain_db\", collection_name: str = \"user_data\",):\n",
    "    \"\"\"\n",
    "    Recreate the retriever dynamically using the metadata in the state.\n",
    "    \"\"\"\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vector_store = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=embeddings,\n",
    "        collection_name=collection_name,\n",
    "    )\n",
    "    return vector_store.as_retriever(search_kwargs={\"k\": 4})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE OF USAGE RUN ONCE: \n",
    "doc_path=\"./data/docs/goldmine.docx\"\n",
    "retriever_doc = process_docs_and_get_retriever(doc_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/docs/goldmine.docx'}, page_content='# Challenges and Opportunities in ASGM\\n\\n\\n\\n## Content:\\n\\nArtisanal and small-scale gold mining (ASGM) is a significant economic activity in the Amazon region. Despite its benefits in providing livelihoods, it faces challenges such as environmental damage, regulatory issues, and health risks. Opportunities exist in adopting sustainable practices, improving technologies, and fostering community-led solutions.\\n\\n\\n\\n#'),\n",
       " Document(metadata={'source': './data/docs/goldmine.docx'}, page_content='# Question:\\n\\nWhat are the most significant challenges and opportunities in artisanal and small-scale gold mining (ASGM) in the Amazon?')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retriever = recreate_retriever()\n",
    "#retriever.invoke('ASGM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from IPython.display import Image, display\n",
    "\n",
    "tools = []\n",
    "\n",
    "retriever = recreate_retriever()\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retriever_tool\",\n",
    "    \"Search and return information for user query.\",\n",
    ")\n",
    "tools.append(retriever_tool)\n",
    "\n",
    "\n",
    "class State(MessagesState):\n",
    "    query: str\n",
    "    doc_path: Optional[str]  # Path of the document being processed\n",
    "    \n",
    "def vector_data(state: State):\n",
    "    if \"doc_path\" in state:\n",
    "        print('\\n\\n********** ADDING DATA TO VECTOR STORE **********\\n\\n')\n",
    "        doc_path = state['doc_path']\n",
    "        # Add documents\n",
    "        process_docs_and_get_retriever(doc_path)\n",
    "        return {'doc_path': \"\"}\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def call_model(state: State):\n",
    "    #global tools\n",
    "    #tools.clear()\n",
    "    messages = state[\"messages\"]\n",
    "    query = state[\"query\"]\n",
    "    sys_msg = SystemMessage(\n",
    "        content=\"\"\"You are a helpful assistant. \n",
    "\n",
    "    Your main task is to assist the user by providing accurate information using the retriever_tool. Always answer based only on the information retrieved with the retriever_tool.\n",
    "\n",
    "    If you do not find the information needed to answer the user's question, clearly state: \n",
    "    'I do not have the information you are looking for.' \n",
    "    Then, politely ask the user to update the knowledge base with relevant details.\n",
    "\n",
    "    Do not provide answers based on assumptions, external knowledge, or unsupported information. Always rely solely on the retrieved content.\"\"\"\n",
    "    )\n",
    "    message = HumanMessage(content=query)\n",
    "    messages.append(message)\n",
    "    #print(f'*******WE SEND THIS TO LLM:\\n\\n{messages}\\n*******')\n",
    "    \n",
    "    # Tool\n",
    "    #retriever = recreate_retriever()\n",
    "    #retriever_tool = create_retriever_tool(\n",
    "    #    retriever,\n",
    "    #    \"retriever_tool\",\n",
    "    #    \"Search and return information for user query.\",\n",
    "    #)\n",
    "    #tools.append(retriever_tool)\n",
    "    \n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    response = llm_with_tools.invoke([sys_msg] + messages)\n",
    "    #print(f'AI RESPONSE: {response}')\n",
    "    return {\"messages\": response}\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"vector_data\", vector_data)\n",
    "workflow.add_node(\"call_model\", call_model)\n",
    "workflow.add_node(\"tools\", ToolNode(tools))  # for the tools\n",
    "\n",
    "workflow.set_entry_point('vector_data')\n",
    "workflow.add_edge('vector_data', 'call_model')\n",
    "workflow.add_conditional_edges(\n",
    "    \"call_model\", tools_condition, path_map=[\"tools\", \"__end__\"]\n",
    ")\n",
    "workflow.add_edge('tools', 'call_model')\n",
    "\n",
    "memory = MemorySaver()\n",
    "react_graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(react_graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_graph(user_input, config, doc_path=None):\n",
    "    \"\"\"\n",
    "    Processes the user input and document path with the graph.\n",
    "\n",
    "    Args:\n",
    "        user_input (str): The user's query.\n",
    "        config (dict): Graph configuration including thread ID.\n",
    "        doc_path (str, optional): Path to the document being processed.\n",
    "\n",
    "    Returns:\n",
    "        str: The response from the graph.\n",
    "    \"\"\"\n",
    "    # Prepare the initial state\n",
    "    state = {}\n",
    "\n",
    "    # Add the query if it exists\n",
    "    if user_input:\n",
    "        state[\"query\"] = user_input\n",
    "\n",
    "    # Add `doc_path` if it exists\n",
    "    if doc_path:\n",
    "        state[\"doc_path\"] = doc_path\n",
    "\n",
    "    # Stream events from the graph\n",
    "    events = react_graph.stream(state, config, stream_mode=\"values\")\n",
    "\n",
    "    response = None  # Initialize response\n",
    "    for event in events:\n",
    "        # Retrieve the last message content from the graph's output\n",
    "        if \"messages\" in event and event[\"messages\"]:\n",
    "            response = event[\"messages\"][-1].content\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "thread_id_number = str(uuid.uuid4())\n",
    "config = {\"configurable\": {\"thread_id\": thread_id_number}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******WE SEND THIS TO LLM:\n",
      "\n",
      "[HumanMessage(content='hi', additional_kwargs={}, response_metadata={}, id='3d730a95-bfbe-4266-b9ca-d51e1bc5efda'), AIMessage(content='How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 343, 'total_tokens': 351, 'completion_time': 0.039406182, 'prompt_time': 0.049887338, 'queue_time': 0.007662730999999999, 'total_time': 0.08929352}, 'model_name': 'llama-3.2-90b-vision-preview', 'system_fingerprint': 'fp_07b97e5459', 'finish_reason': 'stop', 'logprobs': None}, id='run-2dd81e57-3457-42d8-a091-65cc4e6c5c40-0', usage_metadata={'input_tokens': 343, 'output_tokens': 8, 'total_tokens': 351}), HumanMessage(content='What is ASGM?', additional_kwargs={}, response_metadata={})]\n",
      "*******\n",
      "*******WE SEND THIS TO LLM:\n",
      "\n",
      "[HumanMessage(content='hi', additional_kwargs={}, response_metadata={}, id='3d730a95-bfbe-4266-b9ca-d51e1bc5efda'), AIMessage(content='How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 343, 'total_tokens': 351, 'completion_time': 0.039406182, 'prompt_time': 0.049887338, 'queue_time': 0.007662730999999999, 'total_time': 0.08929352}, 'model_name': 'llama-3.2-90b-vision-preview', 'system_fingerprint': 'fp_07b97e5459', 'finish_reason': 'stop', 'logprobs': None}, id='run-2dd81e57-3457-42d8-a091-65cc4e6c5c40-0', usage_metadata={'input_tokens': 343, 'output_tokens': 8, 'total_tokens': 351}), HumanMessage(content='What is ASGM?', additional_kwargs={}, response_metadata={}, id='63a68ee6-085c-467f-b6ab-87ce4e9768b4'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_cr61', 'function': {'arguments': '{\"query\": \"ASGM meaning\"}', 'name': 'retriever_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 365, 'total_tokens': 383, 'completion_time': 0.088230698, 'prompt_time': 0.05269217, 'queue_time': 0.007330779999999995, 'total_time': 0.140922868}, 'model_name': 'llama-3.2-90b-vision-preview', 'system_fingerprint': 'fp_07b97e5459', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-695e198a-e030-4486-906d-1fde32c205a4-0', tool_calls=[{'name': 'retriever_tool', 'args': {'query': 'ASGM meaning'}, 'id': 'call_cr61', 'type': 'tool_call'}], usage_metadata={'input_tokens': 365, 'output_tokens': 18, 'total_tokens': 383}), ToolMessage(content='', name='retriever_tool', id='de0c4bd1-6f4f-41bb-91f3-3dc1a15bc70a', tool_call_id='call_cr61'), HumanMessage(content='What is ASGM?', additional_kwargs={}, response_metadata={})]\n",
      "*******\n",
      "*******WE SEND THIS TO LLM:\n",
      "\n",
      "[HumanMessage(content='hi', additional_kwargs={}, response_metadata={}, id='3d730a95-bfbe-4266-b9ca-d51e1bc5efda'), AIMessage(content='How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 343, 'total_tokens': 351, 'completion_time': 0.039406182, 'prompt_time': 0.049887338, 'queue_time': 0.007662730999999999, 'total_time': 0.08929352}, 'model_name': 'llama-3.2-90b-vision-preview', 'system_fingerprint': 'fp_07b97e5459', 'finish_reason': 'stop', 'logprobs': None}, id='run-2dd81e57-3457-42d8-a091-65cc4e6c5c40-0', usage_metadata={'input_tokens': 343, 'output_tokens': 8, 'total_tokens': 351}), HumanMessage(content='What is ASGM?', additional_kwargs={}, response_metadata={}, id='63a68ee6-085c-467f-b6ab-87ce4e9768b4'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_cr61', 'function': {'arguments': '{\"query\": \"ASGM meaning\"}', 'name': 'retriever_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 365, 'total_tokens': 383, 'completion_time': 0.088230698, 'prompt_time': 0.05269217, 'queue_time': 0.007330779999999995, 'total_time': 0.140922868}, 'model_name': 'llama-3.2-90b-vision-preview', 'system_fingerprint': 'fp_07b97e5459', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-695e198a-e030-4486-906d-1fde32c205a4-0', tool_calls=[{'name': 'retriever_tool', 'args': {'query': 'ASGM meaning'}, 'id': 'call_cr61', 'type': 'tool_call'}], usage_metadata={'input_tokens': 365, 'output_tokens': 18, 'total_tokens': 383}), ToolMessage(content='', name='retriever_tool', id='de0c4bd1-6f4f-41bb-91f3-3dc1a15bc70a', tool_call_id='call_cr61'), HumanMessage(content='What is ASGM?', additional_kwargs={}, response_metadata={}, id='b8de4da7-0664-458b-b7b3-21be8e4f0f0b'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_hy81', 'function': {'arguments': '{\"query\": \"ASGM definition\"}', 'name': 'retriever_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 403, 'total_tokens': 421, 'completion_time': 0.067745269, 'prompt_time': 0.052976543, 'queue_time': 0.005813327, 'total_time': 0.120721812}, 'model_name': 'llama-3.2-90b-vision-preview', 'system_fingerprint': 'fp_9c2a937c92', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0daa0a29-d3eb-491e-a4db-b8b629fcb8b0-0', tool_calls=[{'name': 'retriever_tool', 'args': {'query': 'ASGM definition'}, 'id': 'call_hy81', 'type': 'tool_call'}], usage_metadata={'input_tokens': 403, 'output_tokens': 18, 'total_tokens': 421}), ToolMessage(content='', name='retriever_tool', id='b328e426-35e1-4079-935d-9df9776e45d7', tool_call_id='call_hy81'), HumanMessage(content='What is ASGM?', additional_kwargs={}, response_metadata={})]\n",
      "*******\n",
      "I do not have the information you are looking for. Could you please provide more context or details about ASGM so I can better understand and update the knowledge base for future reference?\n"
     ]
    }
   ],
   "source": [
    "user_query = 'What is ASGM?'\n",
    "response = call_graph(user_input=user_query, config=config)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/Projects/Auto Flujo/Clientes/Upwork/Goldmine/venv_goldmine/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Received message: {'text': '', 'files': ['/private/var/folders/by/d_cc6wt94_d8s97bw7brfc840000gn/T/gradio/2ee10b39b79824734f3699387449efd8fda0e606635a8cf0041d5045e11e856e/forza_pro.docx']}\n",
      "DEBUG: Received file: []\n",
      "\n",
      "\n",
      "********** ADDING DATA TO VECTOR STORE **********\n",
      "\n",
      "\n",
      "ERROR: 'query'\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import uuid\n",
    "\n",
    "# Generate a persistent thread ID once\n",
    "thread_id_number = str(uuid.uuid4())\n",
    "\n",
    "def process_user_input(message, file):\n",
    "    global thread_id_number  # Ensure we're using the same thread ID across calls\n",
    "\n",
    "    # Debug input\n",
    "    print(f\"DEBUG: Received message: {message}\")\n",
    "    print(f\"DEBUG: Received file: {file}\")\n",
    "\n",
    "    # Reuse the existing thread ID for the graph configuration\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id_number}}\n",
    "\n",
    "    # Extract user message\n",
    "    user_text = message.get(\"text\", \"\").strip() if message else \"\"\n",
    "\n",
    "    # Extract doc_path from message[\"files\"]\n",
    "    doc_path = None\n",
    "    if message and \"files\" in message and message[\"files\"]:\n",
    "        doc_path = message[\"files\"][0]  # First file in the list\n",
    "\n",
    "    # Call the graph with the extracted text and/or document path\n",
    "    if user_text or doc_path:  # Ensure at least one input is provided\n",
    "        try:\n",
    "            response = call_graph(user_input=user_text, config=config, doc_path=doc_path)\n",
    "            print(f\"DEBUG: AI Response: {response}\")\n",
    "\n",
    "            # Return meaningful content\n",
    "            if response and isinstance(response, str) and response.strip():\n",
    "                return response\n",
    "            else:\n",
    "                return \"I'm processing your request. Please wait for further results or actions.\"\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: {e}\")\n",
    "            return \"An error occurred while processing your request. Please try again.\"\n",
    "    else:\n",
    "        return \"No message or document provided. Please send a query or attach a document.\"\n",
    "\n",
    "# Gradio interface\n",
    "with gr.Blocks() as app:\n",
    "    chat_interface = gr.ChatInterface(\n",
    "        fn=process_user_input,\n",
    "        type=\"messages\",\n",
    "        multimodal=True,\n",
    "        title=\"Multimodal Chatbot\",\n",
    "        description=\"Ask questions and optionally upload a document (PDF or DOCX).\"\n",
    "    )\n",
    "\n",
    "# Launch the app\n",
    "app.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_goldmine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
